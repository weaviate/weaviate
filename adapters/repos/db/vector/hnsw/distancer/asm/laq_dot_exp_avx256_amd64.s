//go:build !noasm && amd64
// AUTO-GENERATED BY GOAT -- DO NOT EDIT

TEXT Â·laq_dot_exp_avx256(SB), $0-32
	MOVQ x+0(FP), DI
	MOVQ y1+8(FP), SI
	MOVQ y2+16(FP), DX
	MOVQ a1+24(FP), CX
	MOVQ res+32(FP), R8
	MOVQ len+40(FP), R9
	BYTE $0x55                   // pushq	%rbp
	WORD $0x8948; BYTE $0xe5     // movq	%rsp, %rbp
	LONG $0xf8e48348             // andq	$-8, %rsp
	WORD $0x8b41; BYTE $0x01     // movl	(%r9), %eax
	LONG $0x09107ac5             // vmovss	(%rcx), %xmm9                   # xmm9 = mem[0],zero,zero,zero
	WORD $0xf883; BYTE $0x07     // cmpl	$7, %eax
	JG   LBB0_7
	LONG $0x107ac1c4; BYTE $0x08 // vmovss	(%r8), %xmm1                    # xmm1 = mem[0],zero,zero,zero
	WORD $0x01a8                 // testb	$1, %al
	JNE  LBB0_3
	LONG $0xd257e8c5             // vxorps	%xmm2, %xmm2, %xmm2
	WORD $0xc189                 // movl	%eax, %ecx
	WORD $0xf883; BYTE $0x01     // cmpl	$1, %eax
	JNE  LBB0_5

LBB0_22:
	LONG $0x117ac1c4; BYTE $0x10 // vmovss	%xmm2, (%r8)
	WORD $0x8948; BYTE $0xec     // movq	%rbp, %rsp
	BYTE $0x5d                   // popq	%rbp
	BYTE $0xc3                   // retq

LBB0_7:
	LONG $0x187dc2c4; BYTE $0xf1 // vbroadcastss	%xmm9, %ymm6
	LONG $0x187dc2c4; BYTE $0x10 // vbroadcastss	(%r8), %ymm2
	LONG $0x570041c4; BYTE $0xff // vxorps	%xmm15, %xmm15, %xmm15
	WORD $0xf883; BYTE $0x20     // cmpl	$32, %eax
	JB   LBB0_8
	LONG $0xc82978c5             // vmovaps	%xmm9, %xmm0
	LONG $0x570041c4; BYTE $0xff // vxorps	%xmm15, %xmm15, %xmm15
	LONG $0xdb57e0c5             // vxorps	%xmm3, %xmm3, %xmm3
	LONG $0xe457d8c5             // vxorps	%xmm4, %xmm4, %xmm4
	LONG $0xed57d0c5             // vxorps	%xmm5, %xmm5, %xmm5

LBB0_14:
	LONG $0x317de2c4; BYTE $0x3e   // vpmovzxbd	(%rsi), %ymm7           # ymm7 = mem[0],zero,zero,zero,mem[1],zero,zero,zero,mem[2],zero,zero,zero,mem[3],zero,zero,zero,mem[4],zero,zero,zero,mem[5],zero,zero,zero,mem[6],zero,zero,zero,mem[7],zero,zero,zero
	LONG $0xff5bfcc5               // vcvtdq2ps	%ymm7, %ymm7
	LONG $0x317d62c4; WORD $0x0846 // vpmovzxbd	8(%rsi), %ymm8          # ymm8 = mem[0],zero,zero,zero,mem[1],zero,zero,zero,mem[2],zero,zero,zero,mem[3],zero,zero,zero,mem[4],zero,zero,zero,mem[5],zero,zero,zero,mem[6],zero,zero,zero,mem[7],zero,zero,zero
	LONG $0x5b7c41c4; BYTE $0xc0   // vcvtdq2ps	%ymm8, %ymm8
	LONG $0x317d62c4; WORD $0x104e // vpmovzxbd	16(%rsi), %ymm9         # ymm9 = mem[0],zero,zero,zero,mem[1],zero,zero,zero,mem[2],zero,zero,zero,mem[3],zero,zero,zero,mem[4],zero,zero,zero,mem[5],zero,zero,zero,mem[6],zero,zero,zero,mem[7],zero,zero,zero
	LONG $0x5b7c41c4; BYTE $0xc9   // vcvtdq2ps	%ymm9, %ymm9
	LONG $0x317d62c4; WORD $0x1856 // vpmovzxbd	24(%rsi), %ymm10        # ymm10 = mem[0],zero,zero,zero,mem[1],zero,zero,zero,mem[2],zero,zero,zero,mem[3],zero,zero,zero,mem[4],zero,zero,zero,mem[5],zero,zero,zero,mem[6],zero,zero,zero,mem[7],zero,zero,zero
	LONG $0x5b7c41c4; BYTE $0xd2   // vcvtdq2ps	%ymm10, %ymm10
	LONG $0xff59ccc5               // vmulps	%ymm7, %ymm6, %ymm7
	LONG $0xc6593cc5               // vmulps	%ymm6, %ymm8, %ymm8
	LONG $0xce5934c5               // vmulps	%ymm6, %ymm9, %ymm9
	LONG $0x317d62c4; BYTE $0x1a   // vpmovzxbd	(%rdx), %ymm11          # ymm11 = mem[0],zero,zero,zero,mem[1],zero,zero,zero,mem[2],zero,zero,zero,mem[3],zero,zero,zero,mem[4],zero,zero,zero,mem[5],zero,zero,zero,mem[6],zero,zero,zero,mem[7],zero,zero,zero
	LONG $0xd6592cc5               // vmulps	%ymm6, %ymm10, %ymm10
	LONG $0x5b7c41c4; BYTE $0xdb   // vcvtdq2ps	%ymm11, %ymm11
	LONG $0x317d62c4; WORD $0x0862 // vpmovzxbd	8(%rdx), %ymm12         # ymm12 = mem[0],zero,zero,zero,mem[1],zero,zero,zero,mem[2],zero,zero,zero,mem[3],zero,zero,zero,mem[4],zero,zero,zero,mem[5],zero,zero,zero,mem[6],zero,zero,zero,mem[7],zero,zero,zero
	LONG $0x5b7c41c4; BYTE $0xe4   // vcvtdq2ps	%ymm12, %ymm12
	LONG $0x317d62c4; WORD $0x106a // vpmovzxbd	16(%rdx), %ymm13        # ymm13 = mem[0],zero,zero,zero,mem[1],zero,zero,zero,mem[2],zero,zero,zero,mem[3],zero,zero,zero,mem[4],zero,zero,zero,mem[5],zero,zero,zero,mem[6],zero,zero,zero,mem[7],zero,zero,zero
	LONG $0x5b7c41c4; BYTE $0xed   // vcvtdq2ps	%ymm13, %ymm13
	LONG $0x317d62c4; WORD $0x1872 // vpmovzxbd	24(%rdx), %ymm14        # ymm14 = mem[0],zero,zero,zero,mem[1],zero,zero,zero,mem[2],zero,zero,zero,mem[3],zero,zero,zero,mem[4],zero,zero,zero,mem[5],zero,zero,zero,mem[6],zero,zero,zero,mem[7],zero,zero,zero
	LONG $0x5b7c41c4; BYTE $0xf6   // vcvtdq2ps	%ymm14, %ymm14
	LONG $0xa86d62c4; BYTE $0xdf   // vfmadd213ps	%ymm7, %ymm2, %ymm11    # ymm11 = (ymm2 * ymm11) + ymm7
	LONG $0xa86d42c4; BYTE $0xe0   // vfmadd213ps	%ymm8, %ymm2, %ymm12    # ymm12 = (ymm2 * ymm12) + ymm8
	LONG $0xa86d42c4; BYTE $0xe9   // vfmadd213ps	%ymm9, %ymm2, %ymm13    # ymm13 = (ymm2 * ymm13) + ymm9
	LONG $0xb825e2c4; BYTE $0x2f   // vfmadd231ps	(%rdi), %ymm11, %ymm5   # ymm5 = (ymm11 * mem) + ymm5
	LONG $0xb81de2c4; WORD $0x2067 // vfmadd231ps	32(%rdi), %ymm12, %ymm4 # ymm4 = (ymm12 * mem) + ymm4
	LONG $0xb815e2c4; WORD $0x405f // vfmadd231ps	64(%rdi), %ymm13, %ymm3 # ymm3 = (ymm13 * mem) + ymm3
	LONG $0xa86d42c4; BYTE $0xf2   // vfmadd213ps	%ymm10, %ymm2, %ymm14   # ymm14 = (ymm2 * ymm14) + ymm10
	LONG $0xb80d62c4; WORD $0x607f // vfmadd231ps	96(%rdi), %ymm14, %ymm15 # ymm15 = (ymm14 * mem) + ymm15
	WORD $0xc083; BYTE $0xe0       // addl	$-32, %eax
	LONG $0x80ef8348               // subq	$-128, %rdi
	LONG $0x20c68348               // addq	$32, %rsi
	LONG $0x20c28348               // addq	$32, %rdx
	WORD $0xf883; BYTE $0x1f       // cmpl	$31, %eax
	JA   LBB0_14
	WORD $0xf883; BYTE $0x08       // cmpl	$8, %eax
	LONG $0xc82878c5               // vmovaps	%xmm0, %xmm9
	JAE  LBB0_9
	JMP  LBB0_11

LBB0_3:
	WORD $0xb60f; BYTE $0x0e     // movzbl	(%rsi), %ecx
	LONG $0xd12afac5             // vcvtsi2ss	%ecx, %xmm0, %xmm2
	WORD $0xb60f; BYTE $0x0a     // movzbl	(%rdx), %ecx
	LONG $0xd92afac5             // vcvtsi2ss	%ecx, %xmm0, %xmm3
	LONG $0xdb59f2c5             // vmulss	%xmm3, %xmm1, %xmm3
	LONG $0xb931e2c4; BYTE $0xda // vfmadd231ss	%xmm2, %xmm9, %xmm3     # xmm3 = (xmm9 * xmm2) + xmm3
	LONG $0xd257e8c5             // vxorps	%xmm2, %xmm2, %xmm2
	LONG $0xb961e2c4; BYTE $0x17 // vfmadd231ss	(%rdi), %xmm3, %xmm2    # xmm2 = (xmm3 * mem) + xmm2
	WORD $0x488d; BYTE $0xff     // leal	-1(%rax), %ecx
	LONG $0x04c78348             // addq	$4, %rdi
	LONG $0x01c68348             // addq	$1, %rsi
	LONG $0x01c28348             // addq	$1, %rdx
	WORD $0xf883; BYTE $0x01     // cmpl	$1, %eax
	JE   LBB0_22

LBB0_5:
	WORD $0x8941; BYTE $0xc9 // movl	%ecx, %r9d
	WORD $0xc931             // xorl	%ecx, %ecx

LBB0_6:
	LONG $0x0e04b60f                           // movzbl	(%rsi,%rcx), %eax
	LONG $0xd82afac5                           // vcvtsi2ss	%eax, %xmm0, %xmm3
	LONG $0x0a04b60f                           // movzbl	(%rdx,%rcx), %eax
	LONG $0xe02afac5                           // vcvtsi2ss	%eax, %xmm0, %xmm4
	LONG $0xe459f2c5                           // vmulss	%xmm4, %xmm1, %xmm4
	LONG $0xb931e2c4; BYTE $0xe3               // vfmadd231ss	%xmm3, %xmm9, %xmm4     # xmm4 = (xmm9 * xmm3) + xmm4
	LONG $0x0e44b60f; BYTE $0x01               // movzbl	1(%rsi,%rcx), %eax
	LONG $0xd82afac5                           // vcvtsi2ss	%eax, %xmm0, %xmm3
	LONG $0x0a44b60f; BYTE $0x01               // movzbl	1(%rdx,%rcx), %eax
	LONG $0xe82afac5                           // vcvtsi2ss	%eax, %xmm0, %xmm5
	LONG $0x9969e2c4; WORD $0x8f24             // vfmadd132ss	(%rdi,%rcx,4), %xmm2, %xmm4 # xmm4 = (xmm4 * mem) + xmm2
	LONG $0xd559f2c5                           // vmulss	%xmm5, %xmm1, %xmm2
	LONG $0xb931e2c4; BYTE $0xd3               // vfmadd231ss	%xmm3, %xmm9, %xmm2     # xmm2 = (xmm9 * xmm3) + xmm2
	LONG $0x9959e2c4; WORD $0x8f54; BYTE $0x04 // vfmadd132ss	4(%rdi,%rcx,4), %xmm4, %xmm2 # xmm2 = (xmm2 * mem) + xmm4
	LONG $0x02c18348                           // addq	$2, %rcx
	WORD $0x3941; BYTE $0xc9                   // cmpl	%ecx, %r9d
	JNE  LBB0_6
	JMP  LBB0_22

LBB0_8:
	LONG $0xdb57e0c5 // vxorps	%xmm3, %xmm3, %xmm3
	LONG $0xe457d8c5 // vxorps	%xmm4, %xmm4, %xmm4
	LONG $0xed57d0c5 // vxorps	%xmm5, %xmm5, %xmm5

LBB0_9:
	LONG $0x317de2c4; BYTE $0x3e // vpmovzxbd	(%rsi), %ymm7           # ymm7 = mem[0],zero,zero,zero,mem[1],zero,zero,zero,mem[2],zero,zero,zero,mem[3],zero,zero,zero,mem[4],zero,zero,zero,mem[5],zero,zero,zero,mem[6],zero,zero,zero,mem[7],zero,zero,zero
	LONG $0xff5bfcc5             // vcvtdq2ps	%ymm7, %ymm7
	LONG $0xff59ccc5             // vmulps	%ymm7, %ymm6, %ymm7
	LONG $0x317d62c4; BYTE $0x02 // vpmovzxbd	(%rdx), %ymm8           # ymm8 = mem[0],zero,zero,zero,mem[1],zero,zero,zero,mem[2],zero,zero,zero,mem[3],zero,zero,zero,mem[4],zero,zero,zero,mem[5],zero,zero,zero,mem[6],zero,zero,zero,mem[7],zero,zero,zero
	LONG $0x5b7c41c4; BYTE $0xc0 // vcvtdq2ps	%ymm8, %ymm8
	LONG $0xa86d62c4; BYTE $0xc7 // vfmadd213ps	%ymm7, %ymm2, %ymm8     # ymm8 = (ymm2 * ymm8) + ymm7
	LONG $0xb83de2c4; BYTE $0x2f // vfmadd231ps	(%rdi), %ymm8, %ymm5    # ymm5 = (ymm8 * mem) + ymm5
	WORD $0xc083; BYTE $0xf8     // addl	$-8, %eax
	LONG $0x20c78348             // addq	$32, %rdi
	LONG $0x08c68348             // addq	$8, %rsi
	LONG $0x08c28348             // addq	$8, %rdx
	WORD $0xf883; BYTE $0x07     // cmpl	$7, %eax
	JA   LBB0_9

LBB0_11:
	WORD $0xc085             // testl	%eax, %eax
	JE   LBB0_12
	WORD $0x01a8             // testb	$1, %al
	JNE  LBB0_17
	LONG $0xf657c8c5         // vxorps	%xmm6, %xmm6, %xmm6
	WORD $0xc189             // movl	%eax, %ecx
	WORD $0xf883; BYTE $0x01 // cmpl	$1, %eax
	JNE  LBB0_19
	JMP  LBB0_21

LBB0_12:
	LONG $0xf657c8c5 // vxorps	%xmm6, %xmm6, %xmm6
	JMP  LBB0_21

LBB0_17:
	WORD $0xb60f; BYTE $0x0e     // movzbl	(%rsi), %ecx
	LONG $0xf12af2c5             // vcvtsi2ss	%ecx, %xmm1, %xmm6
	WORD $0xb60f; BYTE $0x0a     // movzbl	(%rdx), %ecx
	LONG $0xf92af2c5             // vcvtsi2ss	%ecx, %xmm1, %xmm7
	LONG $0xff59eac5             // vmulss	%xmm7, %xmm2, %xmm7
	LONG $0xb931e2c4; BYTE $0xfe // vfmadd231ss	%xmm6, %xmm9, %xmm7     # xmm7 = (xmm9 * xmm6) + xmm7
	LONG $0xf657c8c5             // vxorps	%xmm6, %xmm6, %xmm6
	LONG $0xb941e2c4; BYTE $0x37 // vfmadd231ss	(%rdi), %xmm7, %xmm6    # xmm6 = (xmm7 * mem) + xmm6
	WORD $0x488d; BYTE $0xff     // leal	-1(%rax), %ecx
	LONG $0x04c78348             // addq	$4, %rdi
	LONG $0x01c68348             // addq	$1, %rsi
	LONG $0x01c28348             // addq	$1, %rdx
	WORD $0xf883; BYTE $0x01     // cmpl	$1, %eax
	JE   LBB0_21

LBB0_19:
	WORD $0x8941; BYTE $0xc9 // movl	%ecx, %r9d
	WORD $0xc931             // xorl	%ecx, %ecx

LBB0_20:
	LONG $0x0e04b60f                           // movzbl	(%rsi,%rcx), %eax
	LONG $0x007ef162; WORD $0xf82a             // vcvtsi2ss	%eax, %xmm16, %xmm7
	LONG $0x0a04b60f                           // movzbl	(%rdx,%rcx), %eax
	LONG $0x007ef162; WORD $0xc02a             // vcvtsi2ss	%eax, %xmm16, %xmm0
	LONG $0xc059eac5                           // vmulss	%xmm0, %xmm2, %xmm0
	LONG $0xb931e2c4; BYTE $0xc7               // vfmadd231ss	%xmm7, %xmm9, %xmm0     # xmm0 = (xmm9 * xmm7) + xmm0
	LONG $0x0e44b60f; BYTE $0x01               // movzbl	1(%rsi,%rcx), %eax
	LONG $0x007ef162; WORD $0xf82a             // vcvtsi2ss	%eax, %xmm16, %xmm7
	LONG $0x0a44b60f; BYTE $0x01               // movzbl	1(%rdx,%rcx), %eax
	LONG $0x007ef162; WORD $0xc82a             // vcvtsi2ss	%eax, %xmm16, %xmm1
	LONG $0x9949e2c4; WORD $0x8f04             // vfmadd132ss	(%rdi,%rcx,4), %xmm6, %xmm0 # xmm0 = (xmm0 * mem) + xmm6
	LONG $0xf159eac5                           // vmulss	%xmm1, %xmm2, %xmm6
	LONG $0xb931e2c4; BYTE $0xf7               // vfmadd231ss	%xmm7, %xmm9, %xmm6     # xmm6 = (xmm9 * xmm7) + xmm6
	LONG $0x9979e2c4; WORD $0x8f74; BYTE $0x04 // vfmadd132ss	4(%rdi,%rcx,4), %xmm0, %xmm6 # xmm6 = (xmm6 * mem) + xmm0
	LONG $0x02c18348                           // addq	$2, %rcx
	WORD $0x3941; BYTE $0xc9                   // cmpl	%ecx, %r9d
	JNE  LBB0_20

LBB0_21:
	LONG $0xc558dcc5               // vaddps	%ymm5, %ymm4, %ymm0
	LONG $0xcb5884c5               // vaddps	%ymm3, %ymm15, %ymm1
	LONG $0xc058f4c5               // vaddps	%ymm0, %ymm1, %ymm0
	LONG $0xc07cffc5               // vhaddps	%ymm0, %ymm0, %ymm0
	LONG $0xc07cffc5               // vhaddps	%ymm0, %ymm0, %ymm0
	LONG $0x197de3c4; WORD $0x01c1 // vextractf128	$1, %ymm0, %xmm1
	LONG $0xc158fac5               // vaddss	%xmm1, %xmm0, %xmm0
	LONG $0xd058cac5               // vaddss	%xmm0, %xmm6, %xmm2
	LONG $0x117ac1c4; BYTE $0x10   // vmovss	%xmm2, (%r8)
	WORD $0x8948; BYTE $0xec       // movq	%rbp, %rsp
	BYTE $0x5d                     // popq	%rbp
	WORD $0xf8c5; BYTE $0x77       // vzeroupper
	BYTE $0xc3                     // retq
