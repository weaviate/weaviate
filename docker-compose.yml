##
# NOTE:
# This docker-compose file is intended only for Weaviate development by contributors and is not meant for end-users.
# Additionally, it should not be used directly with `docker compose up`; instead, please utilize the scripts provided
# under tools/dev for execution.

# To get a docker-compose file to run Weaviate, please follow the instructions at
# https://weaviate.io/developers/weaviate/installation/docker-compose
##
version: '3.4'
services:
  contextionary:
    image: semitechnologies/contextionary:en0.16.0-v1.2.1
    ports:
      - "9999:9999"
    environment:
      EXTENSIONS_STORAGE_MODE: weaviate
      EXTENSIONS_STORAGE_ORIGIN: http://host.docker.internal:8080
      OCCURRENCE_WEIGHT_LINEAR_FACTOR: 0.75
      LOG_LEVEL: debug
  prometheus:
    image: prom/prometheus:v2.46.0
    volumes:
      - ./tools/dev/prometheus_config/:/etc/prometheus/
      - ./data/prometheus:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      # TODO do we want remote write or not?
      # - '--web.enable-remote-write-receiver'
    ports:
      - "9090:9090"
  grafana:
    image: grafana/grafana-oss
    ports:
      - "3000:3000"
    volumes:
      - ./tools/dev/grafana/grafana.ini:/etc/grafana/grafana.ini
      - ./tools/dev/grafana/datasource.yml:/etc/grafana/provisioning/datasources/prometheus.yml
      - ./tools/dev/grafana/datasources/tempo.yml:/etc/grafana/provisioning/datasources/tempo.yml
      - ./tools/dev/grafana/dashboard_provider.yml:/etc/grafana/provisioning/dashboards/dashboards.yml
      - ./tools/dev/grafana/dashboards:/var/lib/grafana/dashboards
  tempo:
    image: grafana/tempo:latest
    command: [ "-config.file=/etc/tempo.yaml" ]
    volumes:
      - ./examples/tempo.yaml:/etc/tempo.yaml
    ports:
      - "3200:3200"   # tempo
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP
    # depends_on:
    #   tempo-s3:
    #     condition: service_healthy
    restart: on-failure
  # TODO
  # tempo-s3:
  #   image: minio/minio
  #   ports:
  #     - "9000:9000"
  #     - "9001:9001"
  #   volumes:
  #     - ./tempo-s3:/data
  #   environment:
  #     MINIO_ROOT_USER: aws_access_key
  #     MINIO_ROOT_PASSWORD: aws_secret_key
  #   entrypoint: sh
  #   command: -c 'mkdir -p /data/tempo-s3 && minio server /data --console-address ":9001"'
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
  #     interval: 5s
  #     timeout: 60s
  #     retries: 3
  #     start_period: 10s
  keycloak:
    image: jboss/keycloak:5.0.0
    environment:
      KEYCLOAK_USER: admin
      KEYCLOAK_PASSWORD: admin
      KEYCLOAK_IMPORT: /tmp/weaviate-realm.json
    volumes:
      - ./tools/dev/keycloak/weaviate-realm.json:/tmp/weaviate-realm.json
    ports:
      - "9090:8080"
  t2v-transformers:
    image: semitechnologies/transformers-inference:baai-bge-small-en-v1.5-onnx
    ports:
      - "8000:8080"
  qna-transformers:
    image: semitechnologies/qna-transformers:distilbert-base-uncased-distilled-squad
    ports:
      - "8001:8080"
  i2v-neural:
    image: semitechnologies/img2vec-pytorch:resnet50
    ports:
      - "8002:8080"
  ner-transformers:
    image: semitechnologies/ner-transformers:latest
    ports:
      - "8003:8080"
  text-spellcheck:
    image: semitechnologies/text-spellcheck-model:pyspellchecker-en
    ports:
      - "8004:8080"
  multi2vec-clip:
    image: semitechnologies/multi2vec-clip:sentence-transformers-clip-ViT-B-32-multilingual-v1
    ports:
      - "8005:8080"
  t2v-transformers-passage:
    image: semitechnologies/transformers-inference:facebook-dpr-ctx_encoder-single-nq-base
    ports:
      - "8006:8080"
  t2v-transformers-query:
    image: semitechnologies/transformers-inference:facebook-dpr-question_encoder-single-nq-base
    ports:
      - "8007:8080"
  sum-transformers:
    image: semitechnologies/sum-transformers:facebook-bart-large-cnn
    ports:
      - "8008:8080"
  reranker-transformers:
    image: semitechnologies/reranker-transformers:cross-encoder-ms-marco-MiniLM-L-6-v2
    ports:
      - "8009:8080"
  t2v-gpt4all:
    image: semitechnologies/gpt4all-inference:all-MiniLM-L6-v2
    ports:
      - "8010:8080"
  multi2vec-bind:
    image: semitechnologies/multi2vec-bind:imagebind
    ports:
      - "8011:8080"
  text2vec-model2vec:
    image: semitechnologies/model2vec-inference:minishlab-potion-retrieval-32M
    ports:
      - "8012:8080"
  backup-s3:
    image: minio/minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./backups-s3:/data
    environment:
      MINIO_ROOT_USER: aws_access_key
      MINIO_ROOT_PASSWORD: aws_secret_key
    entrypoint: sh
    command: -c 'mkdir -p /data/weaviate-backups && minio server /data --console-address ":9001"'
  backup-gcs:
    image: oittaa/gcp-storage-emulator
    ports:
      - "9090:8080"
    volumes:
      - ./backups-gcs:/storage
  backup-azure:
    image: mcr.microsoft.com/azure-storage/azurite
    ports:
      - "10000:10000"
    volumes:
      - ./backups-azure:/data
    command: "azurite --blobHost 0.0.0.0 --blobPort 10000"
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11435:11434"
    volumes:
      - ./_local/ollama:/root/.ollama
      - ./tools/dev/ollama_startup.sh:/ollama_startup.sh
    environment:
      - MODELS_TO_PULL=nomic-embed-text
      - OLLAMA_HOST=0.0.0.0
    entrypoint: ["/bin/sh", "/ollama_startup.sh"]
